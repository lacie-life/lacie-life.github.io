<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Computer Vision Fundamental - [Part 6]" /><meta property="og:locale" content="en" /><meta name="description" content="Chapter 6 - Reconstruction from Multiple Views Not just two, but multiple views. Each new view gives 6 new parameters, but many more point measurements -&gt; ratio params / measurements improves." /><meta property="og:description" content="Chapter 6 - Reconstruction from Multiple Views Not just two, but multiple views. Each new view gives 6 new parameters, but many more point measurements -&gt; ratio params / measurements improves." /><link rel="canonical" href="https://lacie-life.github.io/posts/Computer-Vision-Fundamental-6/" /><meta property="og:url" content="https://lacie-life.github.io/posts/Computer-Vision-Fundamental-6/" /><meta property="og:site_name" content="Life Zero Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-06-15T11:11:11+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Computer Vision Fundamental - [Part 6]" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-06-17T23:58:37+07:00","datePublished":"2022-06-15T11:11:11+07:00","description":"Chapter 6 - Reconstruction from Multiple Views Not just two, but multiple views. Each new view gives 6 new parameters, but many more point measurements -&gt; ratio params / measurements improves.","headline":"Computer Vision Fundamental - [Part 6]","mainEntityOfPage":{"@type":"WebPage","@id":"https://lacie-life.github.io/posts/Computer-Vision-Fundamental-6/"},"url":"https://lacie-life.github.io/posts/Computer-Vision-Fundamental-6/"}</script><title>Computer Vision Fundamental - [Part 6] | Life Zero Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Life Zero Blog"><meta name="application-name" content="Life Zero Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang=""><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://live.staticflickr.com/7347/14119381583_6087a61c73_c_d.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Life Zero Blog</a></div><div class="site-subtitle font-italic">Life is hard but it's fair</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/lacie-life" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['00sao00ios00','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Computer Vision Fundamental - [Part 6]</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Computer Vision Fundamental - [Part 6]</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Life Zero </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Jun 15, 2022, 11:11 AM +0700" >Jun 15, 2022<i class="unloaded">2022-06-15T11:11:11+07:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Fri, Jun 17, 2022, 11:58 PM +0700" >Jun 17, 2022<i class="unloaded">2022-06-17T23:58:37+07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2266 words">12 min read</span></div></div><div class="post-content"><h1 id="chapter-6---reconstruction-from-multiple-views">Chapter 6 - Reconstruction from Multiple Views</h1><p>Not just two, but multiple views. Each new view gives 6 new parameters, but many more point measurements -&gt; ratio params / measurements improves.</p><p>Different approaches:</p><ul><li>trifocal tensors (“trilinear relations” between three images, generalize Fundamental Matrix)<ul><li>Textbooks: Faugeras and Luong 2001; Hartley and Zisserman 2003</ul><li>matrices instead of tensors<ul><li>Textbook: Invitation to 3D vision</ul></ul><h3 id="preimages">Preimages</h3><ul><li>Preimage of a point/line on the image plane: points that get projected to that point/line<li>Preimage of points/lines from multiple views: Intersection of preimages \(\text{preimage}(x_1,\dots,x_m) = \bigcap_i \text{preimage}(x_i)\)</ul><p>The preimage of multiple lines should be a line for the reconstruction to be consistent.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/multiView.png?raw=true" alt="Fig.1" /></p><p>Next denote time-dependent image coordinates by $x(t)$. Parametrize 3D lines in homog. coord. as $L = {X_0 + \mu V}$. $L$’s preimage is a plane $P$ with normal $\ell(t)$, $P = \text{span}(\hat{\ell})$.</p><p>The $\ell$ is orthogonal to points $x$ on $L$: $\ell(t) x(t) = \ell(t) K(t) \Pi_0 g(t) X = 0$ (why?)</p><p>Then $\lambda_i x_i = \Pi_i X$ (relation i-th image of point p &lt;-&gt; world coordinates $X$) and $\ell_i^\top \Pi_i X_0 = \ell_i^\top \Pi_i V = 0$ (relation i-th coimage of $L$ &lt;-&gt; world coordinates $X_0, V$)</p><h3 id="modeling-multi-view-with-point-features">Modeling Multi-View with Point Features</h3><p>Assume we have the world point $X$ represented by points $x_1, \dots, x_m$ in the $m$ images, with depths $\lambda_1, \dots, \lambda_m$. This is modeled by</p>\[\mathcal{I} \vec{\lambda} = \Pi X\]<p>or in more detail,</p>\[\mathcal{I} \vec{\lambda} = \begin{pmatrix} x_1 &amp; &amp; &amp; \\ &amp; x_2 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; x_m \end{pmatrix} \begin{pmatrix}\lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_m \end{pmatrix} = \begin{pmatrix} \Pi_1 \\ \Pi_2 \\ \vdots \\ \Pi_m \end{pmatrix} X = \Pi X\]<ul><li>$\vec{\lambda}$ is the <em>depth scale vector</em><li>$\Pi$ (3m x 4 matrix) is the <em>multiple-view projection matrix</em>, $\Pi_i = \Pi g_i$, and contains the i-th camera rotation as well as the projection<li>$\mathcal{I}$ (3m x m matrix) is the <em>image matrix</em> and contains the “2d” (homogenous) coordinates of projections $x_i$</ul><h5 id="the-rank-constraint">The Rank Constraint</h5><p>Rewrite to obtain:</p>\[N_p u = 0, \qquad \text{ where } N_p := [\Pi, \mathcal{I}], u :=[X; -\vec{\lambda}]\]<p>$N_p$ is a $3m \times (m+4)$ matrix. Since $u$ is in the null space of $N_p$, we get the <strong>rank constraint</strong>:</p>\[\text{rank}(N_p) \leq m+3\]<p>There exists a reconstruction iff this rank constraint holds. Compare with epipolar constraint: contraint is on matrix that only includes camera params and 2d coords, but <strong>no 3d coords</strong>.</p><h5 id="writing-rank-constraint-more-compactly">Writing Rank Constraint more compactly</h5><p>Define $\mathcal{I}^\bot$, where in $\mathcal{I}$, each $x_i$ is substituted by $\widehat{x_i}$ (a 3m x 3m matrix). It annihilates $\mathcal{I}$: $\mathcal{I}^\bot \mathcal{I} = 0$. By multiplying the above $\mathcal{I} \vec{\lambda} = \Pi X$ with it:</p>\[\mathcal{I}^\bot \Pi X = 0\]<p>There exists a reconstruction iff $W_p = \mathcal{I}^\bot \Pi$ does not have full rank:</p>\[\text{rank}(W_p) \leq 3.\]<p>Note: $W_p$ has the form</p>\[W_p = [\widehat{x_1} \Pi_1; \dots; \widehat{x_m} \Pi_m]\]<h3 id="modeling-multi-view-with-line-features">Modeling Multi-View with Line Features</h3><p>Intuition: from a line in two views only, we can’t say anything about the camera motion, because any two line preimages intersect. We can get results from more views.</p><p>Saw already: $\ell_i^\top \Pi_i X_0 = \ell_i^\top \Pi_i V = 0$ for the coimages $\ell_i$ of a line $L$ with base $X_0$, direction $V$.</p><p>Define matrix $W_l = [\ell_1^\top \Pi_1 ; \dots; \ell_m^\top \Pi_m]$ (m x 4 matrix). It maps both $X_0$ and $V$ to 0; these two vectors are linearly independent ($X_0[4] = 1, V[4] = 0$). We get a new rank constraint:</p>\[\text{rank}(W_l) \leq 2\]<h3 id="rank-constraints-geometric-interpretation">Rank Constraints: Geometric Interpretation</h3><h5 id="points-case">Points case</h5><p>For points, we had $W_p X = 0$, $W_p = [\widehat{x_1} \Pi_1; \dots; \widehat{x_m} \Pi_m]$ (3m x 4 matrix). There are 2m lin. indep. rows, which can be interpreted as the normals of 2m planes, and $W_p X = 0$ expresses that $X$ is in the intersection of these planes. The $2m$ planes have a unique intersection iff $\text{rank}(W_p) = 3$.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/fourPlanes-rank-constraint.png?raw=true" alt="Fig.2" /></p><h5 id="lines-case">Lines case</h5><p>The constraint is only meaningful (i.e. actually a constraint) if $m &gt; 2$.</p><h3 id="multiple-view-matrix-of-a-point">Multiple-View Matrix of a Point</h3><p>Goal: further compatify constraints. We are in coordinate frame of first camera; i.e. $\Pi_1 = [I, 0], \Pi_2 = [R_2, T_2], \dots, \Pi_m = [R_m, T_m]$.</p><p>Define $D_p = \begin{pmatrix} \widehat{x_1} &amp; x_1 &amp; 0 \ 0 &amp; 0 &amp; 1\end{pmatrix}$ (4 x 5 matrix, full rank). Multiply with $W_p$ (3m x 4 matrix) to get a 3m x 5 matrix, drop the first three rows and columns and call the submatrix $M_p$:</p>\[M_p = \begin{pmatrix} \widehat{x_2} R_2 x_1 &amp; \widehat{x_2} T_2 \\ \widehat{x_3} R_3 x_1 &amp; \widehat{x_3} T_3 \\ \vdots &amp; \vdots \\ \widehat{x_m} R_m x_1 &amp; \widehat{x_m} T_m \\ \end{pmatrix}\]<p>$M_p$ is a 3(m-1) x 2 matrix. Now: $\text{rank}(W_p) \leq 3 \Leftrightarrow \text{rank}(M_p) \leq 1$, i.e. the two columns are linearly dependent (easy to check and work with!). Proof:</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/matrix_WpDp.png?raw=true" alt="Fig.3" /></p><p>$M_p$ is the <strong>multiple-view matrix</strong>. Summary: there exists a reconstruction iff the matrices $N_p, W_p, M_p$ satisfy:</p>\[\text{rank}(M_p) = \text{rank}(W_p) - 2 = \text{rank}(N_p) - (m+2) \leq 1\]<p>##### Geometric interpretation of Multiple-View Matrix</p><p>The rank constraint implies that the two columns of $M_p$ are linearly dependent. In fact, even \(\lambda_1 \widehat{x_i} R_i x_1 + \widehat{x_i} T_i = 0, i = 2, \dots, m:\) So the scaling factor is equal to the depth value $\lambda_1$.</p><p>(Proof: from the projection equation we know $\lambda_i x_i = \lambda_1 R_i x_1 + T_i$, hence $\lambda_1 \widehat{x_i} R_i x_1 + \widehat{x_i} T_i = 0$.)</p><p>##### $M_p$ =&gt; Epipolar (bilinear) constraints Goal: if we consider only a pair of images, the epipolar constraint should emerge from $M_p$.</p><p>Proof - <em>linear dependence of $\widehat{x_i} R_i x_1$ and $\widehat{x_i} T_i$ implies epipolar constraint $x_i^\top \hat{T}_i R_i x_1 = 0$</em>:</p><p>$\widehat{x_i} T_i$ and $\widehat{x_i} R_i x_1$ are each normals to planes spanned by $x_i, T_i$ and $x_i, R_ix_1$, respectively. Linear dependence of these normals implies: =&gt; $x_i, T_i, R_i x_1$ live in the same plane (<em>coplanar</em>). Therefore $x_i^\top \hat{T}_i R_i x_1 = x_i^\top \hat{T}_i R_i x_1 = 0$.</p><h5 id="m_p--trilinear-constraints">$M_p$ &lt;=&gt; Trilinear constraints</h5><p><strong>Theorem</strong>: <em>a matrix $M = [a_1 b_1; \dots; a_n b_n]$ with $a_i, b_i \in \mathbb{R}^3$ is rank-deficient &lt;=&gt; $a_i b_j^\top - b_i a_j^\top = 0$ for all $i, j$.</em></p><p>Applied to $M_p$, this yields the <em>trilinear constraints</em>:</p>\[\widehat{x_i} (T_i x_1^\top R_j^\top - R_i x_1 T_j^\top) \widehat{x_j} = 0, ~\forall i, j \in [n] \qquad \text{(trilinear constraints)}\]<p>Different than the epipolar constraints, the trilinear constraints actually characterize the rank constraint on $M_p$. Each constraint couples <em>three</em> images: one can show that constraints on pairs of images cannot capture all the information from $m$ images, but these trilinear constraints can.</p><p>Note: we can also obtain the epipolar constraints directly from the trilinear constraints in non-degenerate cases.</p><p>Question: what does the “3 x 3 = 9 scalar trilinear equations” part mean?</p><h5 id="uniqueness-of-the-preimage">Uniqueness of the Preimage</h5><p>This slide was skipped (“a little bit to technical”)</p><h5 id="degenerate-cases">Degenerate cases</h5><p>If $\widehat{x_j} T_j = \widehat{x_j} R_j x_1 = 0$ for some view $j$, then the epipolar constraints cannot be obtained from the trilinear constraints; also the equivalence “trilinear constraints &lt;=&gt; rank constraint” does not hold in degenerate cases.</p><ol><li>If between three images, each pair of epipolar constraints is fulfilled, they determine a unique preimage $p$ - except if all three lines $o_i x_i$ between optical center and image point lie in the same plane.</ol><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/degeneracies-epipolar.png?raw=true" alt="Fig.4" /></p><ol><li>If between three images, all three trilinear constraints hold (3 out of 9 are different considering symmetry), the determine a unique preimage $p$ - except if the three lines $o_i x_i$ are collinear.</ol><p>In the example where all optical centers lie on a line, going from bilinear to trilinear constraints solves the problem.</p><h5 id="summary-rank-of-m_p">Summary: Rank of $M_p$</h5><ul><li>$M_p$ has rank 2 =&gt; no point correspondence; empty preimage.<li>$M_p$ has rank 1 =&gt; point correspondence + <em>unique</em> preimage<li>$M_p$ has rank 0 =&gt; point correspondence, but non-unique preimage</ul><h2 id="multi-view-reconstruction">Multi-View Reconstruction</h2><p>Two approaches:</p><ol><li>cost-function based: maximize some objective function subject to the rank condition =&gt; non-lin. opt. problem: analogous to bundle adjustment<li>decouple structure and motion, like in the 8-point algorithm. Warning: not necessarily practical, since not necessarily optimal in the presence of noise + uncertainty (like the 8-point algorithm)</ol><p>Approach 2 is called <em>factorization approach</em> (because it factors - i.e. decouples - the problem)</p><h3 id="factorization-approach-for-point-features">Factorization Approach for Point Features</h3><p>Assume: $m$ images $x_1^j, \dots, x_m^j$ each of points $p^j$, $j \in [n]$.</p><p>Rank constraint =&gt; columns of $M_{p^j}$ dependent =&gt; (first column) + $\alpha^j$ (second column) = 0. As seen above, $\alpha^j = 1/\lambda_1^j$.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/Pasted-image-20210608164310.png?raw=true" alt="Fig.5" /></p><p>This equation is linear in the camera motion parameters $R_i, T_i$, and can be written as:</p>\[P_i \begin{pmatrix} R_i^s \\ T_i \end{pmatrix} = \begin{pmatrix} x_1^1{}^\top \otimes \widehat{x_i^1} &amp; \alpha^1 \widehat{x_i^1} \\ x_1^2{}^\top \otimes \widehat{x_i^2} &amp; \alpha^2 \widehat{x_i^2} \\ \vdots &amp; \vdots \\ x_1^n{}^\top \otimes \widehat{x_i^n} &amp; \alpha^n \widehat{x_i^n} \end{pmatrix} \begin{pmatrix} R_i^s \\ T_i \end{pmatrix} = 0 \in \mathbb{R}^{3n}\]<p>Here simply things were re-arranged, the $R$ and $T$ matrices stacked in one long vector. One can show: $P_i \in \mathbb{R}^{3n \times 12}$ has rank 11, if more than 6 points (in general position) are given! (Intuition behind 6: 3n rows for n images, but only 2 out of three are lin. indep.)</p><p>=&gt; one-dim. null space =&gt; projection matrix $\Pi_i = (R_i, T_i)$ given up to scalar factor!</p><p>In practice: use &gt; 6 points, compute solution via SVD.</p><p>Like 8-point algorithm: not optimal in the presence of noise and uncertainty.</p><h5 id="decoupling-compared-to-8-point-algorithm">Decoupling compared to 8-point algorithm</h5><p>Difference from 8-point algorithm: structure and motion not fully decoupled, since the 1/depth parameters $\alpha$ are needed to construct $P_i$. However, structure and motion can be iteratively estimated by estimating motion from a structure estimate, and vice versa, until convergence. Advantage: each step has a closed-form solution. This could be initialized by an 8-point algorithm reconstruction and further improve on it using the multi-view information.</p><p>Least-squares solution to find $\alpha_j$ from $R_i, T_i$:</p>\[\alpha^j = - \frac{\sum_{i=2}^m (\widehat{x_i^j} T_i)^\top \widehat{x_i^j} R_i x_1^j}{\sum_{i=2}^m || \widehat{x_i^j} T_i || ^2}\]<p>Another interesting point: Estimating $Pi_i = (R_i, T_i)$ only requires two frames 1 and $j$, but estimating $\alpha$ requires all frames.</p><p>QUESTION: Don’t we get $\alpha_j$ from $M_{p_j}$? (No… we need $R, T$ to get $M_{p_j}$).</p><h3 id="the-multi-view-matrix-for-lines">The Multi-View Matrix for Lines</h3><p>Recall: $\ell_i^\top \Pi_i X_0 = \ell_i^\top \Pi_i V = 0$ for the coimages $\ell_i$ of a line $L$ with base $X_0$, direction $V$; we constructed the multi-view matrix for lines: \(W_l = [\ell_1^\top \Pi_1 ; \dots; \ell_m^\top \Pi_m] \in \mathbb{R}^{m \times 4}\)</p><p>The rank constraint is that $W_l$ should have rank at most 2, since $W_l X_0 = W_l V = 0$. Goal: find more compact representaion; assume $\Pi_1 = (I, 0)$, i.e. first camera is in world coordinates.</p><p>Trick: multiply $W_l$ by 4x5 matrix $D_l$ s.t. last four columns of first row become zero, but keep rank the same.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/matrices-WlDl-lines.png?raw=true" alt="Fig.6" /></p><p>Now since the first column must be lin. indep. because of the zeros in the first row, and the matrix has rank at most 1, the submatrix starting $(W_l D_l)[2:, 2:]$ must have rank 1. This submatrix is called the <em>multi-view matrix for lines</em>.</p>\[M_l = \begin{pmatrix} \ell_2^\top R_2 \widehat{\ell_1} &amp; \ell_2^\top T_2 \\ \vdots &amp; \vdots \\ \ell_m^\top R_m \widehat{\ell_1} &amp; \ell_m^\top T_m \end{pmatrix} \in \mathbb{R}^{(m-1) \times 4}\]<p>The previous rank-2-constraint can be characterized by a rank-1-constraint on $M_l$: A meaningful preimage of $m$ observed lines can only exist if</p>\[\text{rank}(M_l) \leq 1.\]<p>In other words: all rows and all columns must be linearly dependent.</p><h5 id="trilinear-constraints-for-a-line-from-the-rows">Trilinear Constraints for a Line (from the Rows)</h5><p>Since rows of $M_l$ are lin. dep., we have for all $i, j$: $\ell_i^\top R_i \widehat{\ell_1} \sim \ell_j^\top R_j \widehat{\ell_1}$. This states that the three vectors $R_i^\top \ell_j$, $R_j^\top \ell_j$, $\ell_1$ are coplanar. So $R_i^\top \ell_i$ is orthogonal to the cross product of $R_j^\top \ell_j$ and $\ell_1$, which leads to:</p>\[\ell_i^\top R_i \widehat{\ell_1} R_j^\top \ell_j = 0\]<p>Note: this constraint only contains the rotations, not the translations! (Observing lines allows us to directly put constraints on the rotation alone.)</p><p>By the same rank-deficiency lemma from before, we get that the linear dependency of the i-th and j-th row is equivalent to</p>\[\ell_j^\top T_j \ell_i^\top R_i \widehat{\ell_1} - \ell_i^\top T_i \ell_j^\top R_j \widehat{\ell_1} = 0\]<p>This relates the first, i-th and j-th images.</p><p>Both trilinear constraints are equivalent to the rank constraint if $\ell_i^\top T_i \neq 0$.</p><h5 id="generality-of-three-line-constraints">Generality of three-line constraints</h5><p>Any multiview constraint on lines can be reduced to constraints which involve only three lines at a time. (Argument via 2x2 minors of matrix: see slides)</p><h3 id="characterization-of-unique-preimages-for-lines">Characterization of Unique Preimages for Lines</h3><p><strong>Lemma:</strong> <em>Given three camera frames with distinct optical centers and $\ell_1, \ell_2, \ell_3 \in \mathbb{R}^3$ represent three images lines, then their preimage $L$ is uniquely determined if</em> \(\ell_i^\top T_{ji} \ell_k^\top R_{ki} \widehat{\ell_i} - \ell_k^\top T_{ki} \ell_j^\top R_{ji} \widehat{\ell_i} = 0 \quad \forall i, j, k = 1, 2, 3,\) <em>except for one degenerate case: The only degenerate case is that in which the preimages of all $\ell_i$ are the same plane.</em></p><p>Note: this constraint combines the two previous trilinear constraints.</p><p>Equivalent formulation using the rank constraint:</p><p><strong>Theorem:</strong> <em>Given $m$ vectors $\ell_i$ representing images of lines w.r.t. $m$ camera frames, they correspond to the same line in space if the rank of $M_l$ relative to any of the camera frames is 1. If its rank is 0 (i.e. $M_l=0$, the line is determined up to a plane on which then all the camera centers must lie.</em></p><h2 id="summary-of-multi-view-chapter">Summary of Multi-View Chapter</h2><p>| | (Pre)image | coimage | Jointly | |——-|——————————|—————————|—————————| | Point | $\text{rank}(N_p) \leq m+3$ | $\text{rank}(W_p) \leq 3$ | $\text{rank}(M_p) \leq 1$ | | Line | $\text{rank}(N_l) \leq 2m+2$ | $\text{rank}(W_l) \leq 2$ | $\text{rank}(M_l) \leq 1$ |</p><p>The rank constraints guarantee the existence of unique preimages in non-degenerate cases.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/skill/'>Skill</a>, <a href='/categories/computer-vision/'>Computer Vision</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/theory/" class="post-tag no-text-decoration" >Theory</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Computer Vision Fundamental - [Part 6] - Life Zero Blog&url=https://lacie-life.github.io/posts/Computer-Vision-Fundamental-6/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Computer Vision Fundamental - [Part 6] - Life Zero Blog&u=https://lacie-life.github.io/posts/Computer-Vision-Fundamental-6/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Computer Vision Fundamental - [Part 6] - Life Zero Blog&url=https://lacie-life.github.io/posts/Computer-Vision-Fundamental-6/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/ZED2-and-ORB-SLAM3/">ZED2 with ORB-SLAM3 (Stereo-IMU mode) step-by-step</a><li><a href="/posts/Callback-Function-in-C++/">Designing Callbacks in C++</a><li><a href="/posts/ML-for-3D-Geometry-4/">ML for 3D Geometry - Part 4</a><li><a href="/posts/ML-for-3D-Geometry-5/">ML for 3D Geometry - Part 5</a><li><a href="/posts/ML-for-3D-Geometry-10/">ML for 3D Geometry - Part 10</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Computer-Vision-Fundamental-1/"><div class="card-body"> <span class="timeago small" >Jun 10, 2022<i class="unloaded">2022-06-10T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer Vision Fundamental - [Part 1]</h3><div class="text-muted small"><p> These notes are lecture notes on the Computer Vision II - Multiple View Geometry course held in the summer term 2021 by Prof. Daniel Cremers/Prof. Florian Bernard. Ref Chapter 1 - Mathematical Ba...</p></div></div></a></div><div class="card"> <a href="/posts/Computer-Vision-Fundamental-2/"><div class="card-body"> <span class="timeago small" >Jun 11, 2022<i class="unloaded">2022-06-11T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer Vision Fundamental - [Part 2]</h3><div class="text-muted small"><p> Chapter 2 - Representing a Moving Scene Origins of 3D Reconstruction 3D reconstruction is a classical ill-posed problem, as its solutions are not unique (most extreme example: imagine a photograph...</p></div></div></a></div><div class="card"> <a href="/posts/Computer-Vision-Fundamental-3/"><div class="card-body"> <span class="timeago small" >Jun 12, 2022<i class="unloaded">2022-06-12T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer Vision Fundamental - [Part 3]</h3><div class="text-muted small"><p> Chapter 3 - Perspective Projection Goal of MVG: invert the image formation process. One part of the formation process is the camera motion (last lecture). The second one is the projection of point...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Computer-Vision-Fundamental-5/" class="btn btn-outline-primary" prompt="Older"><p>Computer Vision Fundamental - [Part 5]</p></a> <a href="/posts/Computer-Vision-Fundamental-7/" class="btn btn-outline-primary" prompt="Newer"><p>Computer Vision Fundamental - [Part 7]</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Life Zero</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://lacie-life.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
