<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Machine Learning is Fun! - Modern Face Recognition with Deep Learning" /><meta property="og:locale" content="en" /><meta name="description" content="Machine Learning is Fun!: Modern Face Recognition with Deep Learning" /><meta property="og:description" content="Machine Learning is Fun!: Modern Face Recognition with Deep Learning" /><link rel="canonical" href="https://lacie-life.github.io/posts/Machine-Learning-Simple-View-Modern-Face-Recognition-with-Deep-Learning/" /><meta property="og:url" content="https://lacie-life.github.io/posts/Machine-Learning-Simple-View-Modern-Face-Recognition-with-Deep-Learning/" /><meta property="og:site_name" content="Life Zero Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-01-24T11:11:11+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Machine Learning is Fun! - Modern Face Recognition with Deep Learning" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-02-01T19:13:35+07:00","datePublished":"2022-01-24T11:11:11+07:00","description":"Machine Learning is Fun!: Modern Face Recognition with Deep Learning","headline":"Machine Learning is Fun! - Modern Face Recognition with Deep Learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://lacie-life.github.io/posts/Machine-Learning-Simple-View-Modern-Face-Recognition-with-Deep-Learning/"},"url":"https://lacie-life.github.io/posts/Machine-Learning-Simple-View-Modern-Face-Recognition-with-Deep-Learning/"}</script><title>Machine Learning is Fun! - Modern Face Recognition with Deep Learning | Life Zero Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Life Zero Blog"><meta name="application-name" content="Life Zero Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang=""><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://live.staticflickr.com/7347/14119381583_6087a61c73_c_d.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Life Zero Blog</a></div><div class="site-subtitle font-italic">Life is hard but it's fair</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/lacie-life" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['00sao00ios00','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Machine Learning is Fun! - Modern Face Recognition with Deep Learning</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Machine Learning is Fun! - Modern Face Recognition with Deep Learning</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Life Zero </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Jan 24, 2022, 11:11 AM +0700" >Jan 24, 2022<i class="unloaded">2022-01-24T11:11:11+07:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Tue, Feb 1, 2022, 7:13 PM +0700" >Feb 1, 2022<i class="unloaded">2022-02-01T19:13:35+07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2427 words">13 min read</span></div></div><div class="post-content"><h1 id="machine-learning-is-fun-modern-face-recognition-with-deep-learning">Machine Learning is Fun!: Modern Face Recognition with Deep Learning</h1><p>Have you noticed that Facebook has developed an uncanny ability to recognize your friends in your photographs? In the old days, Facebook used to make you to tag your friends in photos by clicking on them and typing in their name. Now as soon as you upload a photo, Facebook tags everyone for you like magic:</p><p><img data-proofer-ignore data-src="https://miro.medium.com/max/502/1*WFi-RK1HU2YrDW3BQXYofQ.gif" alt="Fig.1" /></p><p>This technology is called face recognition. Facebook’s algorithms are able to recognize your friends’ faces after they have been tagged only a few times. It’s pretty amazing technology — Facebook can recognize faces with 98% accuracy which is pretty much as good as humans can do!</p><p>Let’s learn how modern face recognition works! But just recognizing your friends would be too easy. We can push this tech to the limit to solve a more challenging problem — telling Will Ferrell (famous actor) apart from Chad Smith (famous rock musician)!</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/8525a130-7e34-46f0-aae0-7ae6581d0db4.jpeg" alt="Fig.2" /></p><h2 id="how-to-use-machine-learning-on-a-very-complicated-problem">How to use Machine Learning on a Very Complicated Problem</h2><p>So far in Part 1, 2 and 3, we’ve used machine learning to solve isolated problems that have only one step — estimating the price of a house, generating new data based on existing data and telling if an image contains a certain object. All of those problems can be solved by choosing one machine learning algorithm, feeding in data, and getting the result.</p><p>But face recognition is really a series of several related problems:</p><ol><li>First, look at a picture and find all the faces in it<li>Second, focus on each face and be able to understand that even if a face is turned in a weird direction or in bad lighting, it is still the same person.<li>Third, be able to pick out unique features of the face that you can use to tell it apart from other people— like how big the eyes are, how long the face is, etc.<li>Finally, compare the unique features of that face to all the people you already know to determine the person’s name.</ol><p>As a human, your brain is wired to do all of this automatically and instantly. In fact, humans are too good at recognizing faces and end up seeing faces in everyday objects:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/70bc91ad-a798-431a-8142-fe0e2cb6e388.jpeg" alt="Fig.3" /></p><p>Computers are not capable of this kind of high-level generalization (at least not yet…), so we have to teach them how to do each step in this process separately.</p><p>We need to build a pipeline where we solve each step of face recognition separately and pass the result of the current step to the next step. In other words, we will chain together several machine learning algorithms:</p><p><img data-proofer-ignore data-src="https://miro.medium.com/max/700/1*WxBM1lB5WzDjrDXYfi9gtw.gif" alt="Fig.4" /></p><h2 id="face-recognition--step-by-step">Face Recognition — Step by Step</h2><p>Let’s tackle this problem one step at a time. For each step, we’ll learn about a different machine learning algorithm. I’m not going to explain every single algorithm completely to keep this from turning into a book, but you’ll learn the main ideas behind each one and you’ll learn how you can build your own facial recognition system in Python using OpenFace and dlib.</p><h3 id="step-1-finding-all-the-faces">Step 1: Finding all the Faces</h3><p>The first step in our pipeline is face detection. Obviously we need to locate the faces in a photograph before we can try to tell them apart!</p><p>If you’ve used any camera in the last 10 years, you’ve probably seen face detection in action:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/57db465d-2fd9-45f5-8d12-26437d61bcec.png" alt="Fig.5" /></p><p>Face detection is a great feature for cameras. When the camera can automatically pick out faces, it can make sure that all the faces are in focus before it takes the picture. But we’ll use it for a different purpose — finding the areas of the image we want to pass on to the next step in our pipeline.</p><p>Face detection went mainstream in the early 2000’s when Paul Viola and Michael Jones invented a way to detect faces that was fast enough to run on cheap cameras. However, much more reliable solutions exist now. We’re going to use a method invented in 2005 called Histogram of Oriented Gradients — or just HOG for short.</p><p>To find faces in an image, we’ll start by making our image black and white because we don’t need color data to find faces:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/736464f5-f8f5-4bd2-a8e0-7d7fcd12d54d.jpeg" alt="Fig.6" /></p><p>Then we’ll look at every single pixel in our image one at a time. For every single pixel, we want to look at the pixels that directly surrounding it:</p><p><img data-proofer-ignore data-src="https://miro.medium.com/max/700/1*RZS05e_5XXQdofdRx1GvPA.gif" alt="Fig.7" /></p><p>Our goal is to figure out how dark the current pixel is compared to the pixels directly surrounding it. Then we want to draw an arrow showing in which direction the image is getting darker:</p><p><img data-proofer-ignore data-src="https://miro.medium.com/max/500/1*WF54tQnH1Hgpoqk-Vtf9Lg.gif" alt="Fig.8" /></p><p>If you repeat that process for every single pixel in the image, you end up with every pixel being replaced by an arrow. These arrows are called gradients and they show the flow from light to dark across the entire image:</p><p><img data-proofer-ignore data-src="https://miro.medium.com/max/700/1*oTdaElx_M-_z9c_iAwwqcw.gif" alt="Fig.9" /></p><p>This might seem like a random thing to do, but there’s a really good reason for replacing the pixels with gradients. If we analyze pixels directly, really dark images and really light images of the same person will have totally different pixel values. But by only considering the direction that brightness changes, both really dark images and really bright images will end up with the same exact representation. That makes the problem a lot easier to solve!</p><p>But saving the gradient for every single pixel gives us way too much detail. We end up missing the forest for the trees. It would be better if we could just see the basic flow of lightness/darkness at a higher level so we could see the basic pattern of the image.</p><p>To do this, we’ll break up the image into small squares of 16x16 pixels each. In each square, we’ll count up how many gradients point in each major direction (how many point up, point up-right, point right, etc…). Then we’ll replace that square in the image with the arrow directions that were the strongest.</p><p>The end result is we turn the original image into a very simple representation that captures the basic structure of a face in a simple way:</p><p><img data-proofer-ignore data-src="https://miro.medium.com/max/700/1*uHisafuUw0FOsoZA992Jdg.gif" alt="Fig.10" /></p><p>To find faces in this HOG image, all we have to do is find the part of our image that looks the most similar to a known HOG pattern that was extracted from a bunch of other training faces:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/67ce665c-7053-4d4a-b201-d293d68efa02.png" alt="Fig.11" /></p><p>Using this technique, we can now easily find faces in any image:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/a17ff694-95fa-4110-a1b0-4b9d1a0ad630.jpeg" alt="Fig.12" /></p><h3 id="step-2-posing-and-projecting-faces">Step 2: Posing and Projecting Faces</h3><p>Whew, we isolated the faces in our image. But now we have to deal with the problem that faces turned different directions look totally different to a computer:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/b550be88-ea9f-44c4-a884-bae612f3cde1.png" alt="Fig.13" /></p><p>To account for this, we will try to warp each picture so that the eyes and lips are always in the sample place in the image. This will make it a lot easier for us to compare faces in the next steps.</p><p>To do this, we are going to use an algorithm called face landmark estimation. There are lots of ways to do this, but we are going to use the approach invented in 2014 by Vahid Kazemi and Josephine Sullivan.</p><p>The basic idea is we will come up with 68 specific points (called landmarks) that exist on every face — the top of the chin, the outside edge of each eye, the inner edge of each eyebrow, etc. Then we will train a machine learning algorithm to be able to find these 68 specific points on any face:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/64fd23e7-ba7f-41ee-a516-6e0d766241f5.png" alt="Fig.14" /></p><p>Here’s the result of locating the 68 face landmarks on our test image:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/565beb25-6a26-49e2-80cb-77ea04409495.jpeg" alt="Fig.15" /></p><p>Now that we know were the eyes and mouth are, we’ll simply rotate, scale and shear the image so that the eyes and mouth are centered as best as possible. We won’t do any fancy 3d warps because that would introduce distortions into the image. We are only going to use basic image transformations like rotation and scale that preserve parallel lines (called affine transformations):</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/9ea998ad-e888-4d0e-a862-a1ae433e9d81.png" alt="Fig.16" /></p><p>Now no matter how the face is turned, we are able to center the eyes and mouth are in roughly the same position in the image. This will make our next step a lot more accurate.</p><p>If you want to try this step out yourself using Python and dlib, here’s the code for finding face landmarks and here’s the code for transforming the image using those landmarks.</p><h3 id="step-3-encoding-faces">Step 3: Encoding Faces</h3><p>Now we are to the meat of the problem — actually telling faces apart. This is where things get really interesting!</p><p>The simplest approach to face recognition is to directly compare the unknown face we found in Step 2 with all the pictures we have of people that have already been tagged. When we find a previously tagged face that looks very similar to our unknown face, it must be the same person. Seems like a pretty good idea, right?</p><p>There’s actually a huge problem with that approach. A site like Facebook with billions of users and a trillion photos can’t possibly loop through every previous-tagged face to compare it to every newly uploaded picture. That would take way too long. They need to be able to recognize faces in milliseconds, not hours.</p><p>What we need is a way to extract a few basic measurements from each face. Then we could measure our unknown face the same way and find the known face with the closest measurements. For example, we might measure the size of each ear, the spacing between the eyes, the length of the nose, etc. If you’ve ever watched a bad crime show like CSI, you know what I am talking about:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/af3fc5c9-8bb8-4587-83eb-462d471a2992.jpg" alt="Fig.17" /></p><h4 id="the-most-reliable-way-to-measure-a-face">The most reliable way to measure a face</h4><p>Ok, so which measurements should we collect from each face to build our known face database? Ear size? Nose length? Eye color? Something else?</p><p>It turns out that the measurements that seem obvious to us humans (like eye color) don’t really make sense to a computer looking at individual pixels in an image. Researchers have discovered that the most accurate approach is to let the computer figure out the measurements to collect itself. Deep learning does a better job than humans at figuring out which parts of a face are important to measure.</p><p>The solution is to train a Deep Convolutional Neural Network (just like we did in Part 3). But instead of training the network to recognize pictures objects like we did last time, we are going to train it to generate 128 measurements for each face.</p><p>The training process works by looking at 3 face images at a time:</p><ol><li>Load a training face image of a known person<li>Load another picture of the same known person<li>Load a picture of a totally different person</ol><p>Then the algorithm looks at the measurements it is currently generating for each of those three images. It then tweaks the neural network slightly so that it makes sure the measurements it generates for #1 and #2 are slightly closer while making sure the measurements for #2 and #3 are slightly further apart:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/164edace-4bb1-4b6b-ac2e-b51e75c53a3c.png" alt="Fig.18" /></p><p>After repeating this step millions of times for millions of images of thousands of different people, the neural network learns to reliably generate 128 measurements for each person. Any ten different pictures of the same person should give roughly the same measurements.</p><p>Machine learning people call the 128 measurements of each face an embedding. The idea of reducing complicated raw data like a picture into a list of computer-generated numbers comes up a lot in machine learning (especially in language translation). The exact approach for faces we are using was invented in 2015 by researchers at Google but many similar approaches exist.</p><h4 id="encoding-our-face-image">Encoding our face image</h4><p>This process of training a convolutional neural network to output face embeddings requires a lot of data and computer power. Even with an expensive NVidia Telsa video card, it takes about 24 hours of continuous training to get good accuracy.</p><p>But once the network has been trained, it can generate measurements for any face, even ones it has never seen before! So this step only needs to be done once. Lucky for us, the fine folks at OpenFace already did this and they published several trained networks which we can directly use. Thanks Brandon Amos and team!</p><p>So all we need to do ourselves is run our face images through their pre-trained network to get the 128 measurements for each face. Here’s the measurements for our test image:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/98d2f59a-9d39-4fe1-8e43-cc8487ad4540.png" alt="Fig.19" /></p><p>So what parts of the face are these 128 numbers measuring exactly? It turns out that we have no idea. It doesn’t really matter to us. All that we care is that the network generates nearly the same numbers when looking at two different pictures of the same person.</p><h3 id="step-4-finding-the-persons-name-from-the-encoding">Step 4: Finding the person’s name from the encoding</h3><p>This last step is actually the easiest step in the whole process. All we have to do is find the person in our database of known people who has the closest measurements to our test image.</p><p>You can do that by using any basic machine learning classification algorithm. No fancy deep learning tricks are needed. We’ll use a simple linear SVM classifier, but lots of classification algorithms could work.</p><p>All we need to do is train a classifier that can take in the measurements from a new test image and tells which known person is the closest match. Running this classifier takes milliseconds. The result of the classifier is the name of the person!</p><p>So let’s try out our system. First, I trained a classifier with the embeddings of about 20 pictures each of Will Ferrell, Chad Smith and Jimmy Falon:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/a8a81aec-91e2-41bb-a629-93877bf9a7b3.jpeg" alt="Fig.20" /></p><p>Then I ran the classifier on every frame of the famous youtube video of Will Ferrell and Chad Smith pretending to be each other on the Jimmy Fallon show:</p><p><img data-proofer-ignore data-src="https://images.viblo.asia/cba17e21-c66a-40e9-8c60-32f5fd82b985.png" alt="Fig.21" /></p><p>It works! And look how well it works for faces in different poses — even sideways faces!</p><h2 id="running-this-yourself">Running this Yourself</h2><p>Let’s review the steps we followed:</p><ol><li>Encode a picture using the HOG algorithm to create a simplified version of the image. Using this simplified image, find the part of the image that most looks like a generic HOG encoding of a face.<li>Figure out the pose of the face by finding the main landmarks in the face. Once we find those landmarks, use them to warp the image so that the eyes and mouth are centered.<li>Pass the centered face image through a neural network that knows how to measure features of the face. Save those 128 measurements.<li>Looking at all the faces we’ve measured in the past, see which person has the closest measurements to our face’s measurements. That’s our match!</ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/tutorial/" class="post-tag no-text-decoration" >tutorial</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Machine Learning is Fun! - Modern Face Recognition with Deep Learning - Life Zero Blog&url=https://lacie-life.github.io/posts/Machine-Learning-Simple-View-Modern-Face-Recognition-with-Deep-Learning/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Machine Learning is Fun! - Modern Face Recognition with Deep Learning - Life Zero Blog&u=https://lacie-life.github.io/posts/Machine-Learning-Simple-View-Modern-Face-Recognition-with-Deep-Learning/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Machine Learning is Fun! - Modern Face Recognition with Deep Learning - Life Zero Blog&url=https://lacie-life.github.io/posts/Machine-Learning-Simple-View-Modern-Face-Recognition-with-Deep-Learning/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/ZED2-and-ORB-SLAM3/">ZED2 with ORB-SLAM3 (Stereo-IMU mode) step-by-step</a><li><a href="/posts/Callback-Function-in-C++/">Designing Callbacks in C++</a><li><a href="/posts/ML-for-3D-Geometry-4/">ML for 3D Geometry - Part 4</a><li><a href="/posts/ML-for-3D-Geometry-5/">ML for 3D Geometry - Part 5</a><li><a href="/posts/ML-for-3D-Geometry-10/">ML for 3D Geometry - Part 10</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Part-1-Linux-Directory-Structure/"><div class="card-body"> <span class="timeago small" >Sep 13, 2021<i class="unloaded">2021-09-13T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Linux Directory Structure</h3><div class="text-muted small"><p> Linux Directory Structure / – root Every single file and directory starts from the root directory. Only root user has write privilege under this directory. Please note that /root is root us...</p></div></div></a></div><div class="card"> <a href="/posts/Part-2-The-Shell/"><div class="card-body"> <span class="timeago small" >Sep 14, 2021<i class="unloaded">2021-09-14T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>The Shell Theory</h3><div class="text-muted small"><p> The Shell Theory What is The Shell ? A Shell provides you with an interface to the Unix system. It gathers input from you and executes programs based on that input. When a program finishes ex...</p></div></div></a></div><div class="card"> <a href="/posts/Part-3-Basic-Linux-Command/"><div class="card-body"> <span class="timeago small" >Sep 15, 2021<i class="unloaded">2021-09-15T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Basic Linux Command</h3><div class="text-muted small"><p> Basic Linux Command ls - List Directories Content (in windows we call these as a folders) cd - Changes the current directories pwd - Displays the present working direct...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Machine-Learning-Simple-View-Deep-Learning-and-Convolutional-Neural-Networks/" class="btn btn-outline-primary" prompt="Older"><p>Machine Learning is Fun! - Deep Learning and Convolutional Neural Networks</p></a> <a href="/posts/Machine-Learning-Simple-View-Language-Translation-with-Deep-Learning-and-the-Magic-of-Sequences/" class="btn btn-outline-primary" prompt="Newer"><p>Machine Learning is Fun! - Language Translation with Deep Learning and the Magic of Sequences</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Life Zero</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://lacie-life.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
