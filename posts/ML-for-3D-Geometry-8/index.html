<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="ML for 3D Geometry - Part 8" /><meta property="og:locale" content="en" /><meta name="description" content="Reconstructing and Generating Scenes" /><meta property="og:description" content="Reconstructing and Generating Scenes" /><link rel="canonical" href="https://lacie-life.github.io/posts/ML-for-3D-Geometry-8/" /><meta property="og:url" content="https://lacie-life.github.io/posts/ML-for-3D-Geometry-8/" /><meta property="og:site_name" content="Life Zero Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-12-02T11:11:14+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ML for 3D Geometry - Part 8" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-12-03T15:19:36+07:00","datePublished":"2022-12-02T11:11:14+07:00","description":"Reconstructing and Generating Scenes","headline":"ML for 3D Geometry - Part 8","mainEntityOfPage":{"@type":"WebPage","@id":"https://lacie-life.github.io/posts/ML-for-3D-Geometry-8/"},"url":"https://lacie-life.github.io/posts/ML-for-3D-Geometry-8/"}</script><title>ML for 3D Geometry - Part 8 | Life Zero Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Life Zero Blog"><meta name="application-name" content="Life Zero Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang=""><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://live.staticflickr.com/7347/14119381583_6087a61c73_c_d.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Life Zero Blog</a></div><div class="site-subtitle font-italic">Life is hard but it's fair</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/lacie-life" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['00sao00ios00','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>ML for 3D Geometry - Part 8</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ML for 3D Geometry - Part 8</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Life Zero </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Dec 2, 2022, 11:11 AM +0700" >Dec 2, 2022<i class="unloaded">2022-12-02T11:11:14+07:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sat, Dec 3, 2022, 3:19 PM +0700" >Dec 3, 2022<i class="unloaded">2022-12-03T15:19:36+07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1107 words">6 min read</span></div></div><div class="post-content"><h1 id="reconstructing-and-generating-scenes">Reconstructing and Generating Scenes</h1><p>Motivation: make shape generation more accessible, require less expertise</p><ul><li><p>capturing 3d photos (e.g. can change viewpoint a bit)</p><li><p>3d online interaction mimicking live interaction (“mixed reality”)</p><li><p>reconstructing with a Kinect</p><ul><li>one problem: only partial geometry (<em>missing geometry</em>)<ul><li>maybe because the camera didn’t go there<li>or objects are occluded<li>sometimes even from metallic/reflecting surfaces<li>=&gt; need to complete the scans</ul></ul></ul><h2 id="generative-tasks">Generative Tasks</h2><h4 id="scan-completion">Scan completion</h4><p>Fill in missing geometry in an incomplete scan.</p><h4 id="surface-reconstruction">Surface reconstruction</h4><p>we have a room (in this particular case, pretty much completely observed); but only point measurements (point cloud). Go from point measurements to whole continuous surfaces (e.g. implicit representation)</p><p>This could be done by classical surface reconstruction algorithms, but our goal is to learn geometric priors to help the task (to still perform well e.g. if the measurements are more sparse).</p><h4 id="pure-generative-task-scene-generation">Pure generative task: scene generation</h4><p>Sample code from latent space, then construct a plausible scene from it.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/scene_generation.png?raw=true" alt="Fig.1" /></p><h2 id="excursion-generative-tasks-in-2d">Excursion: Generative tasks in 2D</h2><p>Let’s see how similar tasks are tackled in 2D.</p><ul><li>Encoder-Decoder approaches (encode -&gt; decode -&gt; L1/L2 reconstruction loss; problem with this loss: blurry generations)<li>GANs (Generator generates; discriminator must tell real/fake apart)<ul><li>both should train “at a similar pace”</ul><li>Autoregressive models<ul><li>generate not the whole image at once, but pixel-by-pixel (i.e. when you generate the i-th pixel, you already know the i-1 previous ones)<li>examples: PixelRNN, PixelCNN, VQ-VAE, VQ-VAE2</ul></ul><h2 id="scan-completionsurface-reconstruction-tasks-both-appear-in-this-section">Scan completion/Surface reconstruction tasks (both appear in this section)</h2><h4 id="synthetic-vs-true-data">Synthetic vs. true data</h4><p>Synthetic data: perfect ground-truth. Synthetic datasets:</p><ul><li>3D-FRONT (furnished rooms with semantics)<li>ICL-NUIM</ul><p>Fully supervised approaches are fruitful with synthetic data because full ground-truth available.</p><h4 id="sscnet">SSCNet</h4><p>RGB-D image -&gt; geometry occupancy grid (of fixed size) + semantic labels</p><p>Architecture: bunch of convolutions and <em>dilated convolutions</em>.</p><h3 id="scancomplete">ScanComplete</h3><p>(not completely clear what the point is)</p><ul><li>Handle arbitrary-size scenes<li>Trained on crops of scenes<li>complete the scan at different resolutions</ul><p>Also operates in auto-regressive fashion: (8 forward passes instead of one per voxel)</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/autoregressive-scancomplete.png?raw=true" alt="Fig.2" /></p><p>Note: on real-world scan data, the reconstruction is less clean</p><h3 id="learning-just-from-incomplete-real-world-data">Learning just from incomplete real-world data</h3><p>…in a self-supervised way, to get rid of the discrepancy between fake/real data.</p><h4 id="sg-nn-self-supervised-scan-complete-dai-et-al-20">SG-NN: Self-supervised Scan Complete [Dai et al. ‘20]</h4><p>Goal: learn to reconstruct patterns that are missing in a less complete scan, but present in a more complete scan =&gt; self-supervised scan completion!</p><ul><li>reconstructed target scan from several depth frames (still some holes in it)<li>other scan constructed from fewer frames -&gt; more holes<li>train reconstructing more complete frame from less complete frame (ignore space that is unobserved in the target scan in the loss)<ul><li>note: if you don’t ignore the missing space, the network <em>learns to generate holes</em>. Otherwise it manages to fill holes.</ul></ul><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/sg-nn-unsupervised-completion.png?raw=true" alt="Fig.3" /></p><p>Multi-Scale approach as well: dense predictions at coarse level; more sparse predictions at upsampled level.</p><h4 id="spsg-self-supervised-color-generation-dai-et-al-21">SPSG: Self-supervised color generation [Dai et al ‘21’]</h4><p>[[#SG-NN Self-supervised Scan Complete Dai et al ‘20’|Like previous approach]], but also generate color.</p><p>Problems with simple loss like L1: many walls in the input =&gt; everything becomes wall-colored.</p><p>SPSG approach: project back to images (i.e. the actual input data); then use a 2d reconstruction loss, a 2d perceptual loss + a 2d adversarial loss.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/spsg-losses.png?raw=true" alt="Fig.4" /></p><h3 id="leveraging-implicit-reconstruction-networks">Leveraging implicit reconstruction networks</h3><p>i.e. a technique that works well on 3D shapes -&gt; now applied to scenes? =&gt; doesn’t work as easily when working on scenes (not everything centered like for shapes, this makes it harder)</p><h4 id="local-implicit-grids-jiang-et-al-20">Local implicit grids [Jiang et al. ‘20’]</h4><ul><li>Decompose space into smaller patches (where the patches should be: convolutional enc/dec. approach: then fine detail on patches via implicit approach)</ul><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/local-implicit-grids.png?raw=true" alt="Fig.5" /></p><p>Also an advantage: can reconstruct shapes it has never seen before (otherwise, if it has never seen a car, it will turn it into something that is not a car)</p><h4 id="convolutional-occupancy-network-peng-et-al-20">Convolutional Occupancy Network [Peng et al. ‘20’]</h4><p>First convolutional, then implicit occupancy network at the end.</p><ul><li>Advantage: convolutions have translational invariance and can recognize non-centered patterns; implicit representations can reconstruct finer details.</ul><p>First: (coarse) occupancy voxel grid; convolutions =&gt; feature vector per voxel</p><p>Trilinear interpolation: interpolate voxel feature vectors into feature vector for particular point</p><p>Second: feed this feature vector of a point in a implicit occupancy network (shared between decoding locations)</p><h3 id="retrieval-as-reconstruction-exploiting-training-data-as-dictionary">Retrieval as Reconstruction (Exploiting training data as “dictionary”)</h3><p>Usually: condense training data into network weights. But we could leverage the more detailed training data during test time by using it as a dictionary to look up examples of nice constructed objects.</p><p>Advantages/Disadvantages of Retrieval as Reconstruction:</p><ul><li>For example: can be more sure that reconstructed objects are physically plausible (e.g. no chairs without legs etc.)<li>Disadvantage: usually no exact geometric matches.</ul><h4 id="retrievalfuse-siddiqui-et-al-21">RetrievalFuse [Siddiqui et al. ’21]</h4><p>Idea: create initial reconstruction estimate by composing chunks of train data. Then make it consistent afterwards</p><p>QUESTION: how well does this work with unseen objects?</p><p>Database retrieval (k-NN) -&gt; attention-based refinement -&gt; reconstruction</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/retrievalfuse.png?raw=true" alt="Fig.6" /></p><p>kNN via embedding space. Constructed with <em>deep metric learning</em>:</p><ul><li>a point <em>f</em> should be close to similar points <em>f+</em><li>…and far away from dissimilar points <em>f-</em><li>done one triple (<em>f, f+, f-</em>) at a time</ul><p>Use dot product similarity in more complicated expression to compute loss</p><p>k NNs merged together with attention.</p><h4 id="scan2cad-avetisyan-et-al-19">Scan2CAD [Avetisyan et al. ’19]</h4><p>Reconstruct scene by aligning CAD models (e.g. ShapeNet models) to it</p><p>For a point, estimate a heatmap on the candidate CAD models on where this point is likely to be.</p><p>Scan input, point, + candidate CAD models -&gt; Encoded by 3D convs -&gt; output: match (0 or 1), heatmap over CAD model, scale</p><p>Problem: objects aligned independently of each other.</p><h4 id="scenecad-avetisyan-et-al-20">SceneCAD [Avetisyan et al. ’20]</h4><p>Take into account dependency of objects on each other via a GraphNN (used at train time)</p><h2 id="scene-synthesis-task">Scene synthesis task</h2><h4 id="wang-et-al-18">[Wang et al. ‘18]</h4><p>Trick: create scene by iteratively adding objects to a room (easier to generate everything from scratch). It must be learned e.g. which objects appear together usually.</p><p>Loop: partial scene -&gt; decide: continue adding objects? (CNN) -&gt; if yes: predict object category + location (CNN) and place object -&gt; repeat</p><p>(autoregressive approach because of the loop)</p><h2 id="textured-scene-generation">Textured Scene Generation</h2><p>For content creation and visualization: need more than geometry; also textures, materials, lightning…</p><h3 id="texture-optimization-task">Texture optimization task</h3><p>Assume texture is already known (from images), but from motion blur etc., we get blur in the reconstruction. (Challenges: camera pose estimation, motion blur, distortion artifacts, view-dependent materials)</p><h4 id="3dlite-huang-et-al-17">3DLite [Huang et al. ‘17’]</h4><p>Use simple geometric primitives (i.e. planes) and project high-res textures onto these.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/3DLite.png?raw=true" alt="Fig.7" /></p><p>Apparently, uses more classical algorithms mostly. Also, kind of a “handcrafted” pipeline</p><h4 id="adversarial-texture-optimization-huang-et-al-20">Adversarial Texture Optimization [Huang et al. ’20]</h4><p>Leraning an adversarial objective function that knows how real textures look.</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/adversarial-texture-optimization.png?raw=true" alt="Fig.8" /></p><p>In some way use differently aligned perspectives to feed into the discriminator (details a bit unclear)</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/theory/'>Theory</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >Machine Learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ML for 3D Geometry - Part 8 - Life Zero Blog&url=https://lacie-life.github.io/posts/ML-for-3D-Geometry-8/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ML for 3D Geometry - Part 8 - Life Zero Blog&u=https://lacie-life.github.io/posts/ML-for-3D-Geometry-8/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=ML for 3D Geometry - Part 8 - Life Zero Blog&url=https://lacie-life.github.io/posts/ML-for-3D-Geometry-8/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/ZED2-and-ORB-SLAM3/">ZED2 with ORB-SLAM3 (Stereo-IMU mode) step-by-step</a><li><a href="/posts/Callback-Function-in-C++/">Designing Callbacks in C++</a><li><a href="/posts/ML-for-3D-Geometry-4/">ML for 3D Geometry - Part 4</a><li><a href="/posts/ML-for-3D-Geometry-5/">ML for 3D Geometry - Part 5</a><li><a href="/posts/ML-for-3D-Geometry-10/">ML for 3D Geometry - Part 10</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ML-for-3D-Geometry-4/"><div class="card-body"> <span class="timeago small" >Dec 1, 2022<i class="unloaded">2022-12-01T11:11:14+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML for 3D Geometry - Part 4</h3><div class="text-muted small"><p> Shape Generation Goal: be able to generate shapes automatically. Usecases: for example, allow amateurs to create quality 3D models, and professionals to reduce repetitive work. Also, complete 3D s...</p></div></div></a></div><div class="card"> <a href="/posts/ML-for-3D-Geometry-5/"><div class="card-body"> <span class="timeago small" >Dec 1, 2022<i class="unloaded">2022-12-01T11:11:14+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML for 3D Geometry - Part 5</h3><div class="text-muted small"><p> Learning on Different 3D Representations Types of 3D Represenations Volumetric grids =&gt; 3D CNNs Multi-view Point clouds Meshes Volumetric Grids More efficient than dense grid? =&gt;...</p></div></div></a></div><div class="card"> <a href="/posts/ML-for-3D-Geometry-10/"><div class="card-body"> <span class="timeago small" >Dec 2, 2022<i class="unloaded">2022-12-02T11:11:14+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML for 3D Geometry - Part 10</h3><div class="text-muted small"><p> Weak Supervision, n-shot Learning, Data Efficiency Broad motivation for this chapter: We want to use as little (annotated) data as possible, because data collection and data annotation are expensi...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ML-for-3D-Geometry-7/" class="btn btn-outline-primary" prompt="Older"><p>ML for 3D Geometry - Part 7</p></a> <a href="/posts/ML-for-3D-Geometry-9/" class="btn btn-outline-primary" prompt="Newer"><p>ML for 3D Geometry - Part 9</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Life Zero</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://lacie-life.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
