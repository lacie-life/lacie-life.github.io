<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Computer Vision Fundamental - [Part 7]" /><meta property="og:locale" content="en" /><meta name="description" content="Chapter 7 - Bundle Adjustment &amp; Non-Linear Optimization" /><meta property="og:description" content="Chapter 7 - Bundle Adjustment &amp; Non-Linear Optimization" /><link rel="canonical" href="https://lacie-life.github.io/posts/Computer-Vision-Fundamental-7/" /><meta property="og:url" content="https://lacie-life.github.io/posts/Computer-Vision-Fundamental-7/" /><meta property="og:site_name" content="Life Zero Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-06-16T11:11:11+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Computer Vision Fundamental - [Part 7]" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-06-17T23:58:37+07:00","datePublished":"2022-06-16T11:11:11+07:00","description":"Chapter 7 - Bundle Adjustment &amp; Non-Linear Optimization","headline":"Computer Vision Fundamental - [Part 7]","mainEntityOfPage":{"@type":"WebPage","@id":"https://lacie-life.github.io/posts/Computer-Vision-Fundamental-7/"},"url":"https://lacie-life.github.io/posts/Computer-Vision-Fundamental-7/"}</script><title>Computer Vision Fundamental - [Part 7] | Life Zero Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Life Zero Blog"><meta name="application-name" content="Life Zero Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang=""><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://live.staticflickr.com/7347/14119381583_6087a61c73_c_d.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Life Zero Blog</a></div><div class="site-subtitle font-italic">Life is hard but it's fair</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/lacie-life" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['00sao00ios00','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Computer Vision Fundamental - [Part 7]</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Computer Vision Fundamental - [Part 7]</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Life Zero </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Jun 16, 2022, 11:11 AM +0700" >Jun 16, 2022<i class="unloaded">2022-06-16T11:11:11+07:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Fri, Jun 17, 2022, 11:58 PM +0700" >Jun 17, 2022<i class="unloaded">2022-06-17T23:58:37+07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1332 words">7 min read</span></div></div><div class="post-content"><h1 id="chapter-7---bundle-adjustment--non-linear-optimization">Chapter 7 - Bundle Adjustment &amp; Non-Linear Optimization</h1><h2 id="reconstruction-under-noise">Reconstruction under Noise</h2><p>Linear approaches are usually prone to noise. We now assume that $\tilde{x}_1, \tilde{x}_2$ are noisy data points. Goal:</p><ul><li>find $R, T$ <em>as close as possible</em> to the truth<li>such that we get a <em>consistent reconstruction</em></ul><h3 id="bayesian-formulation">Bayesian Formulation</h3><p>(seen before [[09 - Two views II - Structure Reconstruction, Robustness, 4-Point Algorithm#Bayesian approach|here]])</p><p>Maximum aposteriori estimate: involves modeling probability distributions on $SO(3) \times \mathbb{S}^2$. Instead just assume a uniform prior (=&gt; maximum likelihood estimate).</p><h3 id="bundle-adjustment">Bundle Adjustment</h3><p>Assume zero-mean Gaussian noise =&gt; MLE leads to <em>Bundle adjustment</em>: Minimize <em>reprojection error</em></p>\[E(R, T, X_1, \dots, X_n) = \sum_j^N |\tilde{x}^j_1 - \pi(X_j)|^2 + |\tilde{x}^j_2 - \pi(R, T, X_j)|^2\]<p>(two-image case). $\pi(R, T, X_j)$ denotes the projection $\pi(R X_j + T)$.</p><p>Generalization to $m$ images:</p>\[E\big(\{R_i, T_i\}_{i \in [m]}, \{X_j\}_{j \in [N]}\big) = \sum_{i=1}^m \sum_{j=1}^N \theta_{ij} |\tilde{x}_i^j - \pi(R_i, T_i, X_j)|^2\]<p>Here $\theta_{ij}$ is 1 if point $j$ is visible in image $i$, 0 otherwise. Also $T_1 = 0, R_1 = I$. These error functions are non-convex.</p><h5 id="reparametrizations">Reparametrizations</h5><ul><li>represent $X_j$ as $\lambda_1^j x_1^j$, and $\pi(X_j)$ in first image as $x_1^j$<li><div class="table-wrapper"><table><tbody><tr><td>constrained optimization, minimize cost function $E({x_i^j}_j, R, T) = \sum_j^N \sum_i^2<td> <td>x_i^j - \tilde{x}_i^j<td> <td>^2$, subject to consistent geometry constraints: $x_2^j{}^\top \widehat{T} R x_1^j = 0, x_1^j{}^\top e_3 = 1, x_2^j{}^\top e_3 = 1, j \in [N]$.</table></div><ul><li>$R$ and $T$ do not appear in $E$, only in the constraints!</ul></ul><h5 id="constrained-vs-unconstrained">Constrained vs. Unconstrained</h5><div class="table-wrapper"><table><tbody><tr><td>Note: even the “unconstrained” versions are in a way constrained, since $R \in SO(3)$ (and usually $<td> <td>T<td> <td>=1$). But $R$ can be expressed via the Lie algebra: $R = \exp(\hat{\omega})$, where $\hat{\omega} \in so(3)$ is unconstrained.</table></div><h5 id="noise-models">Noise models</h5><p>Quadratic cost functions stem from the Gaussian noise model. Assuming e.g. Poisson noise $P(x) \sim e^{-|x|/\lambda}$ leads to norm terms in the sum without square instead.</p><h5 id="more-comments-on-bundle-adjustment">More comments on Bundle Adjustment</h5><ul><li>“bundles” refers to bundles of light rays<li>approach was first used in the 1950s in photogrammetry<li>typically last step in reconstruction pipeline: First construct an initial solution (e.g. spectral methods), then apply bundle adjustment</ul><h2 id="nonlinear-optimization">Nonlinear Optimization</h2><p>The cost function from [[#Bundle Adjustment]] is called a <em>non-linear least square</em> cost function, because the “modeled 2d point” function $\pi(R_i, T_i, X_j)$ is non-linear.</p><p>Iterative algorithms tend to work well if the function is “not too far from linear”. If the scene is somewhat far away, this increasingly tends to be the case. Iterative algorithms for nonlinear optimization are called <em>non-linear programming</em>.</p><h3 id="gradient-descent">Gradient Descent</h3><p>First-order method, compute local minimum by stepping in the direction of steepest decrease iteratively (“energy decreases the mose” = error function decreases the most).</p><p>Mathematical Setup: $E: \mathbb{R}^n \to \mathbb{R}$ is the cost function. The <em>gradient flow</em> for $E$ is the differential equation \(\begin{cases} x(0) = x_0, \\ \frac{dx}{dt} = -\frac{dE}{dx}(x) \end{cases}\)</p><p>Then the <em>gradient descent</em> is simply the (Euler) discretization of this equation:</p>\[x_{k+1} = x_k - \epsilon \frac{dE}{dx}(x_k), \quad k=0, 1, 2, \dots\]<h5 id="comments-on-gradient-descent">Comments on Gradient Descent</h5><ul><li>very broadly applicable, but more specialized algorithms have better asymptotic convergence rates<ul><li>optimal convergence rates: e.g. Nesterov Momentum (Yurii Nesterov)</ul><li>many iterations for anisotropic cost functions<li>More specialized techniques:<ul><li>conjugate gradient method<li>Newton methods<li>BFGS method</ul></ul><h3 id="least-squares-and-its-variants">Least Squares and its Variants</h3><p>Motivation of this section: clear up terminology.</p><p><em>Linear</em> or <em>Ordinary Least Squares</em> is a method for estimating parameters $x$ in a linear regression model under zero-mean isotropic Gaussian noise:</p>\[a_i = b_i^\top x + \eta_i\]<p>where $b_i \in \mathbb{R}^d$ is the input vector, $a_i \in \mathbb{R}$ the scalar response, $\eta_i ~ N(0, \sigma^2 I)$. Ordinary least squares problem:</p>\[\min_x \sum_i (a_i - x^\top b_i)^2 = \min_x(a - Bx)^\top(a - Bx)\]<p>Historical note: Gauss invented the normal distribution when asking for which noise distribution the optimal estimator was the arithmetic mean.</p><h5 id="weighted-least-squares">Weighted least squares</h5><p>Assume Gaussian noise with a diagonal $\Sigma$: This is called <em>weighted least squares</em>, and we minimize $\sum_i w_i (a_i - x^\top b_i)^2$, $w_i = 1/\sigma_i^2$.</p><p>The cost function from [[#Bundle Adjustment]] corresponds to weighted least squares because of the weights $\theta_{ij}$.</p><h5 id="generalized-least-squares">Generalized least squares</h5><p>Assume general mean-centered Gaussian noise $N(0, \Sigma)$: this gives the <em>generalized least squares</em> problem</p>\[\min_x (a-Bx)^\top \Sigma^{-1} (a-Bx)\]<p>(i.e. minimize the Mahalanobis distance between $a$ and $Bx$). Closed-form solution:</p>\[\hat{x} = (B^\top \Sigma^{-1} B)^{-1} B^\top \Sigma^{-1} a\]<h5 id="least-squares-with-unknown-sigma">Least Squares with unknown $\Sigma$</h5><p>There are iterative estimation algorithms: <em>feasible generalized least squares</em>, <em>iteratively reweighted least squares</em>. Watch out: this problem is non-convex! We usually only converge to local minima.</p><h5 id="iteratively-reweighted-least-squares">Iteratively Reweighted Least Squares</h5><p>Assume there is a known weighting function $w_i(x)$ and a model $f_i(x)$ which replaces $b$. Then solve the minimization problem:</p>\[\min_x \sum_i w_i(x) |a_i - f_i(x)|^2\]<p>To solve it, iteratively solve</p>\[x_{t+1} = \arg\min_x \sum_i w_i(x_t) |a_i - f_i(x)|^2\]<p>If $f_i$ is linear, i.e. $f_i(x) = x^\top b_i$, each subproblem is just a weighted least-squares problem with a closed-form solution.</p><h5 id="non-linear-least-squares">Non-Linear Least Squares</h5><p>Goal: fit observations $(a_i, b_i)$ with a non-linear model $a_i \approx f(b_i, x)$, and minimize $\min_x \sum_i r_i(x)^2$, $r_i(x) = a_i - f(b_i, x)$. This is just the same problem as in [[#Iteratively Reweighted Least Squares]].</p><p>Optimality condition: \(\sum_i r_i \frac{\partial r_i}{\partial x_j} = 0, \quad j \in [d]\)</p><p>Solve this approximately via iterative algorithms, such as <em>Newton methods</em>, <em>Gauss-Newton</em>, or <em>Levenberg-Marquardt</em>.</p><h2 id="iterative-optimization-algorithms">Iterative optimization algorithms</h2><h3 id="newton-methods">Newton Methods</h3><p>Second-order methods: take second derivatives into account.</p><p>Some intution: Fitting a parabola at the point and go to its minimum =&gt; does work well in <em>convex</em> parts of the function, does not work well in <em>concave</em> part.</p><p>We could actually decide at each point whether to use a Newton-method step or a gradient-descent step (also see [[#Levenberg-Marquardt Algorithm]]).</p><p><img data-proofer-ignore data-src="https://github.com/lacie-life/lacie-life.github.io/blob/main/assets/img/post_assest/newton-method-parabolas.png?raw=true" alt="Fig.1" /></p><p>Fit with a quadratic term:</p>\[E(x) \approx E(x_t) + g^\top (x-x_t) + \frac{1}{2} (x - x_t)^\top H (x - x_t)\]<p>Here $g = \frac{dE}{dx}(x_t)$ is the Jacobian, and $\frac{d^2 E}{d x^2} (x_t)$ is the Hessian. The optimality condition is $\frac{dE}{dx} = g + H(x - x_t) = 0$, which yields the iteration rule</p>\[x_{t+1} = x_t - H^{-1} g \qquad \text{(Newton method iteration rule)}\]<p>An additional step size $\gamma \in (0, 1]$ can be added (more conservative):</p>\[x_{t+1} = x_t - \gamma H^{-1} g\]<h5 id="convergence-properties">Convergence Properties</h5><p>Usually converges in <em>fewer iterations</em> than usual gradient descent; around each optimum there is a local neighborhod where the Newton method converges quadratically for $\gamma = 1$, if $H$ is invertible and Lipschitz continuous.</p><ul><li>matrix inversion not trivial on GPUs (not trivially parallelizable)<li>one alternative: solve optimality condition from above iteratively<li>quasi-Newton methods: approximate $H$ or $H^{-1}$ with psd matrix</ul><h3 id="gauss-newton-algorithm">Gauss-Newton Algorithm</h3><p>In the Newton method, there are the gradient $g$ and Hessian $H$:</p><p>\(g_j = 2 \sum_i r_i \frac{\partial r_i}{\partial x_j}\) \(H_{jk} = 2 \sum_i \bigg(\frac{\partial r_i}{\partial x_j}\frac{\partial r_i}{\partial x_k} + r_i \frac{\partial^2 r_i}{\partial x_j \partial x_k} \bigg)\)</p><p>Drop the second-order term in the Hessian for the approximation:</p>\[H_{jk} \approx 2\sum_i \frac{\partial r_i}{\partial x_j}\frac{\partial r_i}{\partial x_k} = 2 \sum_i J_{ij} J_{ik} = 2 J^\top J\]<p>This approximation is guaranteed to be positive definite. Also, $g = J^\top r$. This gives the Gauss-Newton update rule:</p>\[x_{t+1} = x_t + \Delta := x_t - (J^\top J)^{-1} J^\top r\]<ul><li>advantage: no second derivatives, positive definiteness guaranteed<li>approximation valid if the first-order part dominates, i.e. the second-order term we dropped is much smaller in magnitude. In particular, if the function is linear or almost linear</ul><h3 id="damped-newton-and-levenberg-marquardt">Damped Newton and Levenberg-Marquardt</h3><p>Intuition: mixes between gradient descent and Newton method.</p><h5 id="damped-newton-algorithm">Damped Newton Algorithm</h5><p>Modify Newton update rule as follows: \(x_{t+1} = x_t - (H + \lambda I_n)^{-1} g\)</p><ul><li>hybrid between Newton method and gradient descent: $\lambda = 0$ =&gt; pure Newton method. If $\lambda \to \infty$ =&gt; approaches pure gradient descent (with learning rate $\frac{1}{\lambda}$).</ul><h5 id="levenberg-marquardt-algorithm">Levenberg-Marquardt Algorithm</h5><p>Analogously, a damped version for Gauss-Newton (Levenberg 1944):</p>\[x_{t+1} = x_t + \Delta := x_t - (J^\top J + \lambda I_n)^{-1} J^\top r\]<p>A different variant (Marquardt 1963), which is more adaptive and avoids slow convergence in small-gradient directions (and also generally slow convergence if all gradients are small):</p>\[x_{t+1} = x_t + \Delta := x_t - (J^\top J + \lambda \, \text{diag}(J^\top J))^{-1} J^\top r\]</div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/skill/'>Skill</a>, <a href='/categories/computer-vision/'>Computer Vision</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/theory/" class="post-tag no-text-decoration" >Theory</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Computer Vision Fundamental - [Part 7] - Life Zero Blog&url=https://lacie-life.github.io/posts/Computer-Vision-Fundamental-7/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Computer Vision Fundamental - [Part 7] - Life Zero Blog&u=https://lacie-life.github.io/posts/Computer-Vision-Fundamental-7/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Computer Vision Fundamental - [Part 7] - Life Zero Blog&url=https://lacie-life.github.io/posts/Computer-Vision-Fundamental-7/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/ZED2-and-ORB-SLAM3/">ZED2 with ORB-SLAM3 (Stereo-IMU mode) step-by-step</a><li><a href="/posts/Callback-Function-in-C++/">Designing Callbacks in C++</a><li><a href="/posts/ML-for-3D-Geometry-4/">ML for 3D Geometry - Part 4</a><li><a href="/posts/ML-for-3D-Geometry-5/">ML for 3D Geometry - Part 5</a><li><a href="/posts/ML-for-3D-Geometry-10/">ML for 3D Geometry - Part 10</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Computer-Vision-Fundamental-1/"><div class="card-body"> <span class="timeago small" >Jun 10, 2022<i class="unloaded">2022-06-10T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer Vision Fundamental - [Part 1]</h3><div class="text-muted small"><p> These notes are lecture notes on the Computer Vision II - Multiple View Geometry course held in the summer term 2021 by Prof. Daniel Cremers/Prof. Florian Bernard. Ref Chapter 1 - Mathematical Ba...</p></div></div></a></div><div class="card"> <a href="/posts/Computer-Vision-Fundamental-2/"><div class="card-body"> <span class="timeago small" >Jun 11, 2022<i class="unloaded">2022-06-11T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer Vision Fundamental - [Part 2]</h3><div class="text-muted small"><p> Chapter 2 - Representing a Moving Scene Origins of 3D Reconstruction 3D reconstruction is a classical ill-posed problem, as its solutions are not unique (most extreme example: imagine a photograph...</p></div></div></a></div><div class="card"> <a href="/posts/Computer-Vision-Fundamental-3/"><div class="card-body"> <span class="timeago small" >Jun 12, 2022<i class="unloaded">2022-06-12T11:11:11+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer Vision Fundamental - [Part 3]</h3><div class="text-muted small"><p> Chapter 3 - Perspective Projection Goal of MVG: invert the image formation process. One part of the formation process is the camera motion (last lecture). The second one is the projection of point...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Computer-Vision-Fundamental-6/" class="btn btn-outline-primary" prompt="Older"><p>Computer Vision Fundamental - [Part 6]</p></a> <a href="/posts/Computer-Vision-Fundamental-8/" class="btn btn-outline-primary" prompt="Newer"><p>Computer Vision Fundamental - [Part 8]</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Life Zero</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a> <a class="post-tag" href="/tags/theory/">Theory</a> <a class="post-tag" href="/tags/writting/">writting</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/note/">note</a> <a class="post-tag" href="/tags/collection/">collection</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/opencv/">openCV</a> <a class="post-tag" href="/tags/paper/">paper</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://lacie-life.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
